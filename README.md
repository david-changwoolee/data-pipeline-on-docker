# data-pipeline-on-docker

**Project Goal**
- Create a data pipeline cluster for a testing or staging env prior to prod deployment
- Gain hands-on experience building data pipeline using key systems such as Hadoop, Spark, Hive, Airflow, Kafka, Docker

**Core Systems**
- Docker : docker v28.1.1, docker compose v2.35.1
- Hadoop : hadoop v3.4.1 as 'hadoop' custom image based on Ubuntu 
- Hive : hive v3.1.3 as 'hadoop' custom image
- Spark : spark v3.5.5 as 'spark' custom image based on Ubuntu
- Airflow : airflow v2.11.0 as 'airflow' custom image based on Ubuntu
- Kafka : kafka v4.0.0 as ['apache/kafka' official image](https://hub.docker.com/r/apache/kafka)
- MySql : mysql v9.2.0 as ['mysql' official image](https://hub.docker.com/_/mysql) used as Hive Metastore 

**Webui Ports**
- resource manager : localhost:8088
- namenode info : localhost:9870
- datanode info : localhost:9864
- spark history server : localhost:18080
- airflow : localhost:8082
- jupyter notebook : localhost:9000
- metabase graph : localhost:3000

**Architecture**
<img width="1015" height="378" alt="image" src="https://github.com/user-attachments/assets/91b0da52-70ae-4a72-8e07-3c0c177d7568" />

**Data Flow**
1. Airflow dag gets stream data from wikimedia and stores into kafka
   - airflow dag : stream_wiki.py
   - kafka topic : 'wiki'
   - what stream_wiki.py does : reads ['recentchange'(updated content in real time) from wikimedia](https://stream.wikimedia.org/v2/ui/#/?streams=mediawiki.recentchange), filters to get only wiki page update data and stores into kafka 'wiki' topic
2. PySpark reads data from kafka and stores into HDFS
   - jupyter notebook name : kafka_streaming.ipynb
   - HDFS write path : /datalake/data/wiki
3. PySpark reads data from HDFS, transforms, and stores into hive table.
   - airflow dag : aggregate_wiki.py
   - pyspark name : aggregate_wiki.py
   - hive table : default.wiki
   - hive location : /datawarehouse/data/wiki
   - what aggregate_wiki.py does : aggregates to show top 10 wiki page languages by number of wiki page updates
4. Metabase generates graph
   - setup
   - <img width="471" height="762" alt="image" src="https://github.com/user-attachments/assets/65520968-ed64-4d97-b49f-3fe1ddb98221" />
   - visualizing (graph)
   - <img width="319" height="463" alt="image" src="https://github.com/user-attachments/assets/9c527ea8-824f-4e15-a836-31042e98864f" />

**Docker commands**
- docker compose up -d : launch all services
- docker compose up -d hadoop spark : launch only 'hadoop' and 'spark' services
- docker volume ls : list docker volume
- docker volume rm <data-pipeline-on-docker_hadoop_config> : remove docker volume named data-pipeline-on-docker_hadoop_config

**Issues, Causes, and Solutions**
1. when datanode is not excuted
   - spark log : There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
   - hadoop log : ($HADOOP_HOME/logs datanode log) java.io.IOException: Incompatible clusterIDs in /opt/hadoop/hdfs: namenode clusterID = CID-a3ac82a2-d795-4386-ad0d-355d2d35762b; datanode clusterID = CID-d628459c-a72d-4f54-9b3d-8eace53b77c7
   - cause : clusterID is Hadoop cluster's uniq identifier and generated by NameNode. All Datanode has the same clusterID with Namenode for data integrity. When hadoop container executes, Namenode is formatted(by entrypoint.sh) with new clusterID and it occurs clusterID mismatch between Namenode and DataNode(volume).
   - solution : remove docker volume. for example, sudo docker volume rm data-pipeline-on-docker_hadoop_hdfs. Or keep hadoop container alive.
2. when a job which is submitted to YARN uses default queue
   - spark log : [2025-09-03, 13:01:55 UTC] {spark_submit.py:644} INFO - : org.apache.hadoop.yarn.exceptions.YarnException: Failed to submit application_1756904476229_0001 to YARN : Application application_1756904476229_0001 submitted by user root to unknown queue: default
   - cause : usage of unknown queue name. 'default' is a default queue name which is not configured in this project.
   - solution : use a specific queue name. For example, SparkSession.builder.config("spark.yarn.queue", "batch")
3. when spark application read data from HDFS
   - spark log : pyspark.errors.exceptions.captured.AnalysisException: [PATH_NOT_FOUND] Path does not exist: hdfs://hadoop:9000/datalake/data/wiki/date=20250906/hour=06/*.parquet.
   - cause : the HDFS path is not exists because the pyspark streaming doesn't run or insert data into the path.
   - solution : check aggregate_wiki dag schedule interval and [aggregate_wiki code](https://github.com/david-changwoolee/data-pipeline-on-docker/blob/master/spark/pyspark_scripts/aggregate_wiki.py#L17), or upstream pipeline.
4. when try to set db connection in metabase
   - metabase log : Hmm, we couldn't connect to the database. Make sure your Host and Port settings are correct.
   - cause : metabase failed to connect to SparkSQL because spark thrift server was not executed for some reason.
   - solution : run [spark thrift server](https://github.com/david-changwoolee/data-pipeline-on-docker/blob/master/spark/entrypoint.sh#L5)

**To Do**
- Implement HA
- Add test codes

**References**
- apache/kafka official image : https://hub.docker.com/r/apache/kafka
- mysql official image : https://hub.docker.com/_/mysql
- wiki openAPI : https://stream.wikimedia.org/v2/ui/#/?streams=mediawiki.recentchange

