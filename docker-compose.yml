#version: '3.8'
services: 
  hadoop:
    container_name: 'hadoop'
    image: 'hadoop'
    build:
      context: .
      dockerfile: hadoop/Dockerfile
    stdin_open: true
    tty: true
    ports:
      - '8088:8088'
      - '9870:9870'
      - '9864:9864'
      - '19888:19888'
      - '8042:8042'
      - '8888:8888'
    volumes:
      - hadoop_config:/opt/hadoop/etc/hadoop
      - hadoop_hdfs:/opt/hadoop/hdfs
      - hive_config:/opt/hive/conf
        #    depends_on:
        #      - mysql
  spark:
    container_name: 'spark'
    image: 'spark'
    build:
      context: .
      dockerfile: spark/Dockerfile
    stdin_open: true
    tty: true
    ports:
      - '8080:8080'
      - '8081:8081'
      - '18080:18080'
      - '4040:4040'
      - '7077:7077'
      - '9000:9000'
    volumes:
      - hadoop_config:/opt/hadoop/etc/hadoop:ro
      - hive_config:/opt/spark/conf:ro
      - ./spark/jupyter:/root/jupyter
      - ./spark/conf/jupyter_notebook_config.py:/root/.jupyter/jupyter_notebook_config.py
  mysql:
    container_name: 'mysql'
    image: 'mysql'
    ports:
      - '3306:3306'
      - '8083:8080'
    volumes:
      - mysql:/var/lib/mysql
      - ./mysql/conf:/docker-entrypoint-initdb.d
    environment:
      MYSQL_ROOT_PASSWORD: root
  grafana:
    container_name: 'grafana'
    image: 'grafana/grafana'
    ports:
      - '3000:3000'
  airflow:
    container_name: 'airflow'
    image: 'airflow'
    build:
      context: .
      dockerfile: airflow/Dockerfile
    stdin_open: true
    tty: true
    ports:
      - '8082:8082'
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./spark/pyspark_scripts:/opt/airflow/pyspark_scripts
      - hadoop_config:/opt/hadoop/etc/hadoop:ro
    depends_on:
      - mysql 
        #  hive:
        #    container_name: 'hive'
        #    image: 'hive'
        #    ports:
        #      - '10000:10000'
        #      - '9083:9083'
        #      - '10002:10002'
        #    volumes:
        #      - hadoop_config:/opt/hadoop/etc/hadoop:ro
        #      - hive_config:/opt/hive/conf
        #    depends_on:
        #      - mysql
volumes:
  hadoop_config:
  hadoop_hdfs:
  hive_config:
  mysql:
